name: Scrape, Clean, and Upload to MinIO (Docker)

on:
  schedule:
    - cron: '0 *11 * * *'  # Every hour
  workflow_dispatch:
  

jobs:
  scrape_clean_upload:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v3

      - name: ğŸ³ Start MinIO in Docker
        run: |
          docker run -d -p 9000:9000 -p 9001:9001 \
            -e MINIO_ROOT_USER=minioadmin \
            -e MINIO_ROOT_PASSWORD=minioadmin \
            --name minio \
            quay.io/minio/minio server /data --console-address ":9001"

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: ğŸ“¦ Install dependencies
        run: pip install -r requirements.txt

      - name: ğŸ•¸ï¸ Run scraping and cleaning script
        run: python scraper/run_scraper.py

      - name: ğŸ§ª Install MinIO Client (mc)
        run: |
          wget https://dl.min.io/client/mc/release/linux-amd64/mc
          chmod +x mc
          sudo mv mc /usr/local/bin/

      - name: â˜ï¸ Upload cleaned data to MinIO
        run: |
          set -e
          for i in {1..10}; do
            curl -s http://localhost:9000/minio/health/ready && break
            echo "Waiting for MinIO to be ready..."
            sleep 3
          done

          mc alias set localminio http://localhost:9000 minioadmin minioadmin --api S3v4
          mc mb --ignore-existing localminio/mybucket
          mc cp -r scraper/output/ localminio/mybucket/

      - name: âœ… List uploaded files
        run: mc ls localminio/mybucket/

      - name: ğŸ“¦ Upload output files as GitHub Artifact
        uses: actions/upload-artifact@v4
        with:
          name: scraped-book-data
          path: scraper/output/

