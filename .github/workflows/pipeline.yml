name: Scrape, Clean, and Upload to MinIO (Docker)

on:
  schedule:
    - cron: '0 */1 * * *'  # Every hour
  workflow_dispatch:

jobs:
  scrape_clean_upload:
    runs-on: ubuntu-latest

    services:
      minio:
        image: minio/minio
        ports:
          - 9000:9000
        env:
          MINIO_ROOT_USER: minioadmin
          MINIO_ROOT_PASSWORD: minioadmin
        options: >-
          --health-cmd="curl -f http://localhost:9000/minio/health/ready || exit 1"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5
        args: server /data  # âœ… Correct replacement for 'command'

    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v3

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: ğŸ“¦ Install dependencies
        run: pip install -r requirements.txt

      - name: ğŸ•¸ï¸ Run scraping and cleaning script
        run: python scraper/run_scraper.py

      - name: ğŸ§ª Install MinIO Client (mc)
        run: |
          wget https://dl.min.io/client/mc/release/linux-amd64/mc
          chmod +x mc
          sudo mv mc /usr/local/bin/

      - name: â˜ï¸ Upload cleaned data to MinIO
        run: |
          set -e
          for i in {1..10}; do
            curl -s http://localhost:9000/minio/health/ready && break
            echo "Waiting for MinIO..."
            sleep 3
          done

          mc alias set localminio http://localhost:9000 minioadmin minioadmin --api S3v4
          mc mb --ignore-existing localminio/mybucket
          mc cp -r cleaned_data/ localminio/mybucket/

      - name: âœ… List uploaded files
        run: mc ls localminio/mybucket/
